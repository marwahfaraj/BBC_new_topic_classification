{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "\n",
    "data= pd.read_csv('data/bbc_news_text_complexity_summarization.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define colors based on user preference\n",
    "colors = ['#FF0000', '#000000', '#808080', '#D3D3D3', '#FFFFFF']  # red, black, gray, light gray, white\n",
    "\n",
    "# Plot topic distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "data['labels'].value_counts().plot(kind='bar', color=colors, edgecolor='black')\n",
    "plt.title('Distribution of Topics in BBC News Dataset')\n",
    "plt.xlabel('Topics')\n",
    "plt.ylabel('Number of Articles')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting the colors for the distribution of topics plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='labels', data=data, order=data['labels'].value_counts().index, palette=['#B22222', '#555555', '#222222', '#C0C0C0', '#8B0000'])\n",
    "plt.title('Distribution of Topics', color='black')\n",
    "plt.xlabel('Topic', color='black')\n",
    "plt.ylabel('Count', color='black')\n",
    "plt.xticks(color='black')\n",
    "plt.yticks(color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bar chart illustrates the distribution of articles across five topics in the BBC News dataset: Sport, Business, Politics, Entertainment, and Tech. The dataset is relatively balanced, with Sport and Business topics having the highest representation, each around 500 articles. Politics follows closely, while Entertainment and Tech have fewer entries. This balanced distribution suggests that the dataset is well-suited for classification tasks, as each topic has a comparable number of samples. However, slight imbalances could impact the modelâ€™s accuracy for less-represented categories like Tech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting the colors for the boxplot of number of sentences per topic\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='labels', y='no_sentences', data=data, palette=['#B22222', '#555555', '#222222', '#C0C0C0', '#8B0000'])\n",
    "plt.title('Distribution of Number of Sentences per Topic', color='black')\n",
    "plt.xlabel('Topic', color='black')\n",
    "plt.ylabel('Number of Sentences', color='black')\n",
    "plt.xticks(color='black')\n",
    "plt.yticks(color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting the colors for Flesch Reading Ease Score per topic\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='labels', y='Flesch Reading Ease Score', data=data, palette=['#B22222', '#555555', '#222222', '#C0C0C0', '#8B0000'])\n",
    "plt.title('Flesch Reading Ease Score by Topic', color='black')\n",
    "plt.xlabel('Topic', color='black')\n",
    "plt.ylabel('Flesch Reading Ease Score', color='black')\n",
    "plt.xticks(color='black')\n",
    "plt.yticks(color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The box plot shows the Flesch Reading Ease Score distribution for each topic, providing insights into readability:\n",
    "\n",
    "Politics and Business articles have a wider range and tend to have lower readability scores, suggesting they are more complex.\n",
    "Entertainment and Sport articles generally have higher readability scores, indicating simpler language, which might make them more accessible to a broader audience.\n",
    "Tech articles have a mid-range readability, likely due to specific terminology but generally accessible language.\n",
    "These readability variations may affect classification accuracy, as certain topics might have more distinctive linguistic patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting the colors for Dale-Chall Readability Score per topic\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='labels', y='Dale-Chall Readability Score', data=data, palette=['#B22222', '#555555', '#222222', '#C0C0C0', '#8B0000'])\n",
    "plt.title('Dale-Chall Readability Score by Topic', color='black')\n",
    "plt.xlabel('Topic', color='black')\n",
    "plt.ylabel('Dale-Chall Readability Score', color='black')\n",
    "plt.xticks(color='black')\n",
    "plt.yticks(color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all text into a single string and split into words\n",
    "all_words = \" \".join(data['text']).lower().split()\n",
    "\n",
    "# Define an extended set of stopwords to remove common, meaningless words\n",
    "extended_stopwords = set([\n",
    "    'the', 'and', 'to', 'of', 'in', 'for', 'that', 'on', 'with', 'as', 'is', \n",
    "    'was', 'at', 'by', 'an', 'be', 'this', 'which', 'or', 'from', 'but', 'it', \n",
    "    'are', 'not', 'have', 'has', 'had', 'we', 'will', 'can', 'more', 'about', \n",
    "    'their', 'been', 'after', 'they', 'you', 'all', 'out', 'up', 'if', 'who', 'what',\n",
    "    'he', 'said', 'his', 'mr', 'she', 'her', 'they', 'them', 'its', \n",
    "    'would', 'one', 'could', 'new', 'also', 'people', 'us', 'over', 'first', \n",
    "    'last', 'two', 'may', 'many', 'much', 'even', 'make', 'made', 'time', \n",
    "    'year', 'years', 'still', 'know', 'back', 'way', 'right', 'say', 'day', 'days',\n",
    "    'now', 'so', 'like', 'a', 'i', 'just', 'only', 'get', 'told', 'no', 'do', 'such', \n",
    "    'best', 'being', 'other', 'some', 'when', 'were', 'than', 'against', 'should', \n",
    "    't', 'yes', 'said', 'well'\n",
    "])\n",
    "\n",
    "# Filter out stopwords\n",
    "filtered_words_final = [word for word in all_words if word.isalpha() and word not in extended_stopwords]\n",
    "word_counts_final = Counter(filtered_words_final)\n",
    "\n",
    "# Get the 25 most common words and sort them in descending order of frequency\n",
    "top_25_words_final = word_counts_final.most_common(25)\n",
    "words_sorted, counts_sorted = zip(*sorted(top_25_words_final, key=lambda x: x[1], reverse=True))\n",
    "\n",
    "# Plot the final refined top 25 words in a horizontal bar chart with the longest bar at the top\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(y=list(words_sorted), x=list(counts_sorted), palette=['#B22222']*25)\n",
    "plt.title('Top 25 Words by Frequency (Final Refined - Longest at Top)', color='black')\n",
    "plt.xlabel('Count', color='black')\n",
    "plt.ylabel('Words', color='black')\n",
    "plt.xticks(color='black')\n",
    "plt.yticks(color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Recreate all_words by combining all text entries\n",
    "all_words = \" \".join(data['text']).lower().split()\n",
    "\n",
    "# Define extended stopwords as specified\n",
    "extended_stopwords = set([\n",
    "    'the', 'and', 'to', 'of', 'in', 'for', 'that', 'on', 'with', 'as', 'is', \n",
    "    'was', 'at', 'by', 'an', 'be', 'this', 'which', 'or', 'from', 'but', 'it', \n",
    "    'are', 'not', 'have', 'has', 'had', 'we', 'will', 'can', 'more', 'about', \n",
    "    'their', 'been', 'after', 'they', 'you', 'all', 'out', 'up', 'if', 'who', 'what',\n",
    "    'he', 'said', 'his', 'mr', 'she', 'her', 'they', 'them', 'its', \n",
    "    'would', 'one', 'could', 'new', 'also', 'people', 'us', 'over', 'first', \n",
    "    'last', 'two', 'may', 'many', 'much', 'even', 'make', 'made', 'time', \n",
    "    'year', 'years', 'still', 'know', 'back', 'way', 'right', 'say', 'day', 'days',\n",
    "    'now', 'so', 'like', 'a', 'i', 'just', 'only', 'get', 'told', 'no', 'do', 'such', \n",
    "    'best', 'being', 'other', 'some', 'when', 'were', 'than', 'against', 'should', \n",
    "    't', 'yes', 'said', 'well'\n",
    "])\n",
    "\n",
    "# Filter out stopwords\n",
    "filtered_words_final = [word for word in all_words if word.isalpha() and word not in extended_stopwords]\n",
    "\n",
    "# Generate the word cloud\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white', colormap='Reds').generate(\" \".join(filtered_words_final))\n",
    "\n",
    "# Display the word cloud\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud of Most Frequent Words in BBC News Dataset', color='black')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
